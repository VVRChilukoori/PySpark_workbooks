{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark 1.6 Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating table df_rtable(raw table) using pyspark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rtable = sqlContext.createDataFrame(\n",
    "    [(\"Green\", \"1\", \"1.3\", \"DescriptionONE\"),\n",
    "     (\"Green\", \"0\", \"1.445\", \"DescriptionONE\"),\n",
    "     (\"Blue\", \"4\", \"1.2\", \"DescriptionTWO\"),\n",
    "     (\"Red\", \"5\", \"1.3\", \"Description THREE\"),\n",
    "     (\"Yellow\", \"7\", \"1.325\", \"Description Four\"), \n",
    "    (\"Red\", \"9\", \"1.4\", \"DescriptionONE\"),\n",
    "    (\"Red\", \"6\", \"1.72158\", \"Description THREE\"),\n",
    "     (\"Blue\", \"5\", \"1\", \"DescriptionONE\")],\n",
    "    (\"Input 1\", \"Input 2\", \"Input 3\", \"Description\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To view the loaded raw table in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-----------------+\n",
      "|Input 1|Input 2|Input 3|      Description|\n",
      "+-------+-------+-------+-----------------+\n",
      "|  Green|      1|    1.3|   DescriptionONE|\n",
      "|  Green|      0|  1.445|   DescriptionONE|\n",
      "|   Blue|      4|    1.2|   DescriptionTWO|\n",
      "|    Red|      5|    1.3|Description THREE|\n",
      "| Yellow|      7|  1.325| Description Four|\n",
      "|    Red|      9|    1.4|   DescriptionONE|\n",
      "|    Red|      6|1.72158|Description THREE|\n",
      "|   Blue|      5|      1|   DescriptionONE|\n",
      "+-------+-------+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rtable.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To the Schema of the loaded table (Gives details of column names, data types, and other restrictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Input 1: string (nullable = true)\n",
      " |-- Input 2: string (nullable = true)\n",
      " |-- Input 3: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rtable.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing library functions required for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python fucntion to check for spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacerem_upper(x):\n",
    "    pos = x.find(' ')\n",
    "    #print(pos)\n",
    "    if pos != - 1:\n",
    "        y = x[:pos] + x[pos+1 : ].upper()\n",
    "        return y\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceDeleteUDF = udf(spacerem_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.functions.UserDefinedFunction"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spaceDeleteUDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying UDF to \"Description column\" for the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upper2 = df_rtable.withColumn(\"Description\", spaceDeleteUDF(\"Description\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+----------------+\n",
      "|Input 1|Input 2|Input 3|     Description|\n",
      "+-------+-------+-------+----------------+\n",
      "|  Green|      1|    1.3|  DescriptionONE|\n",
      "|  Green|      0|  1.445|  DescriptionONE|\n",
      "|   Blue|      4|    1.2|  DescriptionTWO|\n",
      "|    Red|      5|    1.3|DescriptionTHREE|\n",
      "| Yellow|      7|  1.325| DescriptionFOUR|\n",
      "|    Red|      9|    1.4|  DescriptionONE|\n",
      "|    Red|      6|1.72158|DescriptionTHREE|\n",
      "|   Blue|      5|      1|  DescriptionONE|\n",
      "+-------+-------+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_upper2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages required to perform other tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the format of a column in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upper3 =df_upper2.select(df_upper2['Input 1'], df_upper2['Input 2'], df_upper2['Input 3'].cast('float'), \n",
    "                            df_upper2['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_upper31 = df_upper2.withColumn('Input 3', df_upper2['Input 3'].cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Input 1: string (nullable = true)\n",
      " |-- Input 2: string (nullable = true)\n",
      " |-- Input 3: float (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df_upper31.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+----------------+\n",
      "|Input 1|Input 2|Input 3|     Description|\n",
      "+-------+-------+-------+----------------+\n",
      "|  Green|      1|    1.3|  DescriptionONE|\n",
      "|  Green|      0|  1.445|  DescriptionONE|\n",
      "|   Blue|      4|    1.2|  DescriptionTWO|\n",
      "|    Red|      5|    1.3|DescriptionTHREE|\n",
      "| Yellow|      7|  1.325| DescriptionFOUR|\n",
      "|    Red|      9|    1.4|  DescriptionONE|\n",
      "|    Red|      6|1.72158|DescriptionTHREE|\n",
      "|   Blue|      5|    1.0|  DescriptionONE|\n",
      "+-------+-------+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df_upper31.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_upper4 = df_upper31.withColumn('Input 3',format_number(df_upper31['Input 3'],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upper41 = df_upper2.withColumn('Input 3', format_number((df_upper2['Input 3'].cast('float')),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the schemas for the columns in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Input 1: string (nullable = true)\n",
      " |-- Input 2: string (nullable = true)\n",
      " |-- Input 3: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_upper41.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+----------------+\n",
      "|Input 1|Input 2|Input 3|     Description|\n",
      "+-------+-------+-------+----------------+\n",
      "|  Green|      1| 1.3000|  DescriptionONE|\n",
      "|  Green|      0| 1.4450|  DescriptionONE|\n",
      "|   Blue|      4| 1.2000|  DescriptionTWO|\n",
      "|    Red|      5| 1.3000|DescriptionTHREE|\n",
      "| Yellow|      7| 1.3250| DescriptionFOUR|\n",
      "|    Red|      9| 1.4000|  DescriptionONE|\n",
      "|    Red|      6| 1.7216|DescriptionTHREE|\n",
      "|   Blue|      5| 1.0000|  DescriptionONE|\n",
      "+-------+-------+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_upper41.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from pyspark.sql import SQLContext\n",
    "#df = data.selectExpr(\"Name as name\", \"askdaosdka as age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rtable2 = sqlContext.createDataFrame([(\"Green\", \"Night\"),\n",
    "                                        (\"Yellow\", \"Morning\"),\n",
    "                                        (\"Red\", \"Afternoon\"),\n",
    "                                        (\"Blue\",\"Evening\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|    _1|       _2|\n",
      "+------+---------+\n",
      "| Green|    Night|\n",
      "|Yellow|  Morning|\n",
      "|   Red|Afternoon|\n",
      "|  Blue|  Evening|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rtable2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rtable2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rtable3 = df_rtable2.withColumnRenamed('_1','Input 1').withColumnRenamed('_2','Day Period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Input 1|Day Period|\n",
      "+-------+----------+\n",
      "|  Green|     Night|\n",
      "| Yellow|   Morning|\n",
      "|    Red| Afternoon|\n",
      "|   Blue|   Evening|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rtable3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rtable31 = df_rtable2.withColumnRenamed('_1','Input 5').withColumnRenamed('_2','Day Period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Input 5|Day Period|\n",
      "+-------+----------+\n",
      "|  Green|     Night|\n",
      "| Yellow|   Morning|\n",
      "|    Red| Afternoon|\n",
      "|   Blue|   Evening|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rtable31.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftjoin=df_upper4.join(df_rtable3,['Input 1'],\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+----------------+----------+\n",
      "|Input 1|Input 2|Input 3|     Description|Day Period|\n",
      "+-------+-------+-------+----------------+----------+\n",
      "|   Blue|      4| 1.2000|  DescriptionTWO|   Evening|\n",
      "|   Blue|      5| 1.0000|  DescriptionONE|   Evening|\n",
      "|  Green|      1| 1.3000|  DescriptionONE|     Night|\n",
      "|  Green|      0| 1.4450|  DescriptionONE|     Night|\n",
      "| Yellow|      7| 1.3250| DescriptionFOUR|   Morning|\n",
      "|    Red|      5| 1.3000|DescriptionTHREE| Afternoon|\n",
      "|    Red|      9| 1.4000|  DescriptionONE| Afternoon|\n",
      "|    Red|      6| 1.7216|DescriptionTHREE| Afternoon|\n",
      "+-------+-------+-------+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftjoin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For random generation of Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql.functions import lit\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python function to create random dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_rand(a):\n",
    "    date_YYYY = str(random.randint(1950, 2000))\n",
    "    date_MM   = str(random.randint(01, 12)).zfill(02)\n",
    "    date_DD   = str(random.randint(01, 28)).zfill(02)\n",
    "    date_sep  = '-'\n",
    "    return  date_YYYY + date_MM + date_DD \n",
    "\n",
    "udfdate_rand = udf(date_rand, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftjoin = leftjoin.withColumn(\"Date\",lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftjoin_w_date = leftjoin.withColumn(\"Date\", udfdate_rand(\"Date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+----------------+----------+--------+\n",
      "|Input 1|Input 2|Input 3|     Description|Day Period|    Date|\n",
      "+-------+-------+-------+----------------+----------+--------+\n",
      "|   Blue|      4| 1.2000|  DescriptionTWO|   Evening|19921008|\n",
      "|   Blue|      5| 1.0000|  DescriptionONE|   Evening|19750312|\n",
      "|  Green|      1| 1.3000|  DescriptionONE|     Night|19921008|\n",
      "|  Green|      0| 1.4450|  DescriptionONE|     Night|19750312|\n",
      "| Yellow|      7| 1.3250| DescriptionFOUR|   Morning|19510116|\n",
      "|    Red|      5| 1.3000|DescriptionTHREE| Afternoon|19510116|\n",
      "|    Red|      9| 1.4000|  DescriptionONE| Afternoon|19540723|\n",
      "|    Red|      6| 1.7216|DescriptionTHREE| Afternoon|19590414|\n",
      "+-------+-------+-------+----------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftjoin_w_date.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Input 1: string (nullable = true)\n",
      " |-- Input 2: string (nullable = true)\n",
      " |-- Input 3: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Day Period: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftjoin_w_date.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftjoin_w_date = leftjoin_w_date.withColumn(\"Input 3\",leftjoin_w_date[\"Input 3\"].cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Input 1: string (nullable = true)\n",
      " |-- Input 2: string (nullable = true)\n",
      " |-- Input 3: float (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Day Period: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftjoin_w_date.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_calc =leftjoin_w_date.filter((leftjoin_w_date['Input 3'] < 1.31 ) \n",
    "                                 & (leftjoin_w_date['Input 1'] != 'Red') \n",
    "                                 & (leftjoin_w_date['Input 1'] != 'Green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+--------------+----------+--------+\n",
      "|Input 1|Input 2|Input 3|   Description|Day Period|    Date|\n",
      "+-------+-------+-------+--------------+----------+--------+\n",
      "|   Blue|      4|    1.2|DescriptionTWO|   Evening|19561222|\n",
      "|   Blue|      5|    1.0|DescriptionONE|   Evening|19940610|\n",
      "+-------+-------+-------+--------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_calc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Input 1: string (nullable = true)\n",
      " |-- Input 2: string (nullable = true)\n",
      " |-- Input 3: float (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Day Period: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_calc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_list = leftjoin_w_date.select('Date').collect()\n",
    "\n",
    "date_array = [int(i.Date) for i in date_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(date_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19731015,\n",
       " 19780121,\n",
       " 19870717,\n",
       " 19870717,\n",
       " 19930415,\n",
       " 19930415,\n",
       " 19960425,\n",
       " 19960425]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defg = sorted(date_array)\n",
    "defg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(defg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(defg)%2 == 0:\n",
    "    date_cmp1 = defg[(len(defg)/2)-1]\n",
    "    date_cmp2 = defg[(len(defg)/2)]\n",
    "    if date_cmp1 == date_cmp2:\n",
    "        date_cmp = date_cmp1\n",
    "    else:\n",
    "        date_cmp = date_cmp1\n",
    "else:\n",
    "    date_cmp = defg[(len(defg)/2)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19870717"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_cmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Input 1: string (nullable = true)\n",
      " |-- Input 2: string (nullable = true)\n",
      " |-- Input 3: float (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Day Period: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftjoin_w_date.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leftjoin_w_date = leftjoin_w_date.withColumn(\"Date\",leftjoin_w_date[\"Date\"].cast('int')).withColumn(\"Input 2\",leftjoin_w_date[\"Input 2\"].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Input 1: string (nullable = true)\n",
      " |-- Input 2: integer (nullable = true)\n",
      " |-- Input 3: float (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Day Period: string (nullable = true)\n",
      " |-- Date: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftjoin_w_date.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flag_func(a,b):\n",
    "    if a > date_cmp and b > 1:\n",
    "        flag = 1 \n",
    "    else:\n",
    "        flag = 0 \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udf_falg_func = udf(flag_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leftjoin_w_flag = leftjoin_w_date.withColumn('flag', udf_falg_func(\"Date\",\"Input 2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+----------------+----------+--------+----+\n",
      "|Input 1|Input 2|Input 3|     Description|Day Period|    Date|flag|\n",
      "+-------+-------+-------+----------------+----------+--------+----+\n",
      "|   Blue|      4|    1.2|  DescriptionTWO|   Evening|19680522|   0|\n",
      "|   Blue|      5|    1.0|  DescriptionONE|   Evening|19660822|   0|\n",
      "|  Green|      1|    1.3|  DescriptionONE|     Night|20000314|   0|\n",
      "|  Green|      0|  1.445|  DescriptionONE|     Night|19920608|   0|\n",
      "| Yellow|      7|  1.325| DescriptionFOUR|   Morning|19690328|   0|\n",
      "|    Red|      5|    1.3|DescriptionTHREE| Afternoon|19931126|   1|\n",
      "|    Red|      9|    1.4|  DescriptionONE| Afternoon|19570114|   0|\n",
      "|    Red|      6| 1.7216|DescriptionTHREE| Afternoon|19700807|   0|\n",
      "+-------+-------+-------+----------------+----------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftjoin_w_flag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = leftjoin_w_flag.groupby('Description').agg(F.sum(\"Input 3\")/(F.min(\"Input 2\"))).alias('sumbymin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------------------------------------------------------------------------------------+\n",
      "|     Description|((sum(Input 3),mode=Complete,isDistinct=false) / (min(Input 2),mode=Complete,isDistinct=false))|\n",
      "+----------------+-----------------------------------------------------------------------------------------------+\n",
      "|  DescriptionONE|                                                                                           null|\n",
      "|DescriptionTHREE|                                                                             0.6043200016021728|\n",
      "| DescriptionFOUR|                                                                             0.1892857210976737|\n",
      "|  DescriptionTWO|                                                                            0.30000001192092896|\n",
      "+----------------+-----------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def function_5_to_10(a,b):\n",
    "    df_upper4  = a\n",
    "    df_rtable2 = b\n",
    "    \n",
    "    df_rtable3 = df_rtable2.withColumnRenamed('_1','Input 1').withColumnRenamed('_2','Day Period')\n",
    "    \n",
    "    df_rtable3.show()\n",
    "    \n",
    "    leftjoin = df_upper4.join(df_rtable3,['Input 1'],\"left\")\n",
    "    \n",
    "    leftjoin.show()\n",
    "    \n",
    "    def date_rand(a):\n",
    "        date_YYYY = str(random.randint(1950, 2000))\n",
    "        date_MM   = str(random.randint(01, 12)).zfill(02)\n",
    "        date_DD   = str(random.randint(01, 28)).zfill(02)\n",
    "        date_sep  = '-'\n",
    "        return  date_YYYY + date_MM + date_DD \n",
    "\n",
    "    udfdate_rand = udf(date_rand, StringType())\n",
    "    \n",
    "    leftjoin = leftjoin.withColumn(\"Date\",lit(0))\n",
    "    \n",
    "    leftjoin_w_date = leftjoin.withColumn(\"Date\", udfdate_rand(\"Date\"))\n",
    "    \n",
    "    leftjoin_w_date = leftjoin_w_date.withColumn(\"Input 3\",leftjoin_w_date[\"Input 3\"].cast('float'))\n",
    "    \n",
    "    leftjoin_w_date.show()\n",
    "    \n",
    "    df_calc =leftjoin_w_date.filter((leftjoin_w_date['Input 3'] < 1.31 ) \n",
    "                                 & (leftjoin_w_date['Input 1'] != 'Red') \n",
    "                                 & (leftjoin_w_date['Input 1'] != 'Green'))\n",
    "    \n",
    "    df_calc.show()\n",
    "    \n",
    "    date_list = leftjoin_w_date.select('Date').collect()\n",
    "\n",
    "    date_array = [int(i.Date) for i in date_list]\n",
    "    \n",
    "    defg = sorted(date_array)\n",
    "    \n",
    "    if len(defg)%2 == 0:\n",
    "        date_cmp1 = defg[(len(defg)/2)-1]\n",
    "        date_cmp2 = defg[(len(defg)/2)]\n",
    "        if date_cmp1 == date_cmp2:\n",
    "            date_cmp = date_cmp1\n",
    "        else:\n",
    "            date_cmp = date_cmp1\n",
    "    else:\n",
    "        date_cmp = defg[(len(defg)/2)-1]\n",
    "        \n",
    "    leftjoin_w_date = leftjoin_w_date.withColumn(\"Date\",leftjoin_w_date[\"Date\"].cast('int'))\n",
    "    leftjoin_w_date = leftjoin_w_date.withColumn(\"Input 2\",leftjoin_w_date[\"Input 2\"].cast('int'))\n",
    "    \n",
    "    def flag_func(a,b):\n",
    "        if a > date_cmp and b > 1:\n",
    "            flag = 1 \n",
    "        else:\n",
    "            flag = 0 \n",
    "        return flag\n",
    "    \n",
    "    udf_falg_func = udf(flag_func)\n",
    "    \n",
    "    leftjoin_w_flag = leftjoin_w_date.withColumn('flag', udf_falg_func(\"Date\",\"Input 2\"))\n",
    "    \n",
    "    leftjoin_w_flag.show()\n",
    "    \n",
    "    df1 = leftjoin_w_flag.groupby('Description').agg(F.sum(\"Input 3\")/(F.min(\"Input 2\"))).alias('sumbymin')\n",
    "    df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Input 1|Day Period|\n",
      "+-------+----------+\n",
      "|  Green|     Night|\n",
      "| Yellow|   Morning|\n",
      "|    Red| Afternoon|\n",
      "|   Blue|   Evening|\n",
      "+-------+----------+\n",
      "\n",
      "+-------+-------+-------+----------------+----------+\n",
      "|Input 1|Input 2|Input 3|     Description|Day Period|\n",
      "+-------+-------+-------+----------------+----------+\n",
      "|   Blue|      4| 1.2000|  DescriptionTWO|   Evening|\n",
      "|   Blue|      5| 1.0000|  DescriptionONE|   Evening|\n",
      "|  Green|      1| 1.3000|  DescriptionONE|     Night|\n",
      "|  Green|      0| 1.4450|  DescriptionONE|     Night|\n",
      "| Yellow|      7| 1.3250| DescriptionFOUR|   Morning|\n",
      "|    Red|      5| 1.3000|DescriptionTHREE| Afternoon|\n",
      "|    Red|      9| 1.4000|  DescriptionONE| Afternoon|\n",
      "|    Red|      6| 1.7216|DescriptionTHREE| Afternoon|\n",
      "+-------+-------+-------+----------------+----------+\n",
      "\n",
      "+-------+-------+-------+----------------+----------+--------+\n",
      "|Input 1|Input 2|Input 3|     Description|Day Period|    Date|\n",
      "+-------+-------+-------+----------------+----------+--------+\n",
      "|   Blue|      4|    1.2|  DescriptionTWO|   Evening|19560615|\n",
      "|   Blue|      5|    1.0|  DescriptionONE|   Evening|19590401|\n",
      "|  Green|      1|    1.3|  DescriptionONE|     Night|19570114|\n",
      "|  Green|      0|  1.445|  DescriptionONE|     Night|19700807|\n",
      "| Yellow|      7|  1.325| DescriptionFOUR|   Morning|19900213|\n",
      "|    Red|      5|    1.3|DescriptionTHREE| Afternoon|19560615|\n",
      "|    Red|      9|    1.4|  DescriptionONE| Afternoon|19590401|\n",
      "|    Red|      6| 1.7216|DescriptionTHREE| Afternoon|19900213|\n",
      "+-------+-------+-------+----------------+----------+--------+\n",
      "\n",
      "+-------+-------+-------+--------------+----------+--------+\n",
      "|Input 1|Input 2|Input 3|   Description|Day Period|    Date|\n",
      "+-------+-------+-------+--------------+----------+--------+\n",
      "|   Blue|      4|    1.2|DescriptionTWO|   Evening|19780723|\n",
      "|   Blue|      5|    1.0|DescriptionONE|   Evening|19970220|\n",
      "+-------+-------+-------+--------------+----------+--------+\n",
      "\n",
      "+-------+-------+-------+----------------+----------+--------+----+\n",
      "|Input 1|Input 2|Input 3|     Description|Day Period|    Date|flag|\n",
      "+-------+-------+-------+----------------+----------+--------+----+\n",
      "|   Blue|      4|    1.2|  DescriptionTWO|   Evening|19580409|   0|\n",
      "|   Blue|      5|    1.0|  DescriptionONE|   Evening|19880407|   1|\n",
      "|  Green|      1|    1.3|  DescriptionONE|     Night|19581116|   0|\n",
      "|  Green|      0|  1.445|  DescriptionONE|     Night|19830601|   0|\n",
      "| Yellow|      7|  1.325| DescriptionFOUR|   Morning|19591228|   0|\n",
      "|    Red|      5|    1.3|DescriptionTHREE| Afternoon|19760325|   1|\n",
      "|    Red|      9|    1.4|  DescriptionONE| Afternoon|19810811|   1|\n",
      "|    Red|      6| 1.7216|DescriptionTHREE| Afternoon|19800826|   1|\n",
      "+-------+-------+-------+----------------+----------+--------+----+\n",
      "\n",
      "+----------------+-----------------------------------------------------------------------------------------------+\n",
      "|     Description|((sum(Input 3),mode=Complete,isDistinct=false) / (min(Input 2),mode=Complete,isDistinct=false))|\n",
      "+----------------+-----------------------------------------------------------------------------------------------+\n",
      "|  DescriptionONE|                                                                                           null|\n",
      "|DescriptionTHREE|                                                                             0.6043200016021728|\n",
      "| DescriptionFOUR|                                                                             0.1892857210976737|\n",
      "|  DescriptionTWO|                                                                            0.30000001192092896|\n",
      "+----------------+-----------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = function_5_to_10(df_upper4,df_rtable2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
